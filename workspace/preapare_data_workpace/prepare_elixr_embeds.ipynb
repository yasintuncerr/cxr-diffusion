{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 23:05:34.009566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740600334.037736 2554781 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740600334.046542 2554781 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 23:05:34.076813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get absolute path to project root\n",
    "project_root = Path(os.path.abspath('')).parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "nih_dataset_root_dir = os.getenv(\"NIH_CXR14_DATASET_DIR\")\n",
    "elixr_dataset_root_dir = nih_dataset_root_dir + \"/elixr\"\n",
    "elixr_c_14_dataset_root_dir = elixr_dataset_root_dir + \"/elixrc\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import  ELIXR\n",
    "from src.datasets import NIHImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT IMAGE EMBEDDINGS FROM NIH-CXR-DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740600344.035478 2554781 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22456 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:88:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/NODULE_MASS/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/NODULE_MASS/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/NODULE_MASS/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/AIRSPACE_OPACITY/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/FRACTURE/dense/bias:0' shape=(1,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Heads/NODULE_MASS/dense/kernel:0' shape=(1376, 1) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "Max len 16\n"
     ]
    }
   ],
   "source": [
    "elixrc_path = elixr_dataset_root_dir + \"/elixrc\"\n",
    "if os.path.exists(elixrc_path):\n",
    "    list_dir = os.listdir(elixrc_path)\n",
    "    if len(list_dir) > 0:\n",
    "        raise ValueError(\"ELIXR-C14 dataset already exists. Exiting to prevent overwriting. If you want to re-generate the dataset, delete the existing dataset directory and re-run this script.\")\n",
    "else:\n",
    "    os.makedirs(elixrc_path, exist_ok=True)\n",
    "\n",
    "dataset = NIHImageDataset(nih_dataset_root_dir + \"/original\")\n",
    "\n",
    "elixr_model = ELIXR(\n",
    "    use_elixrb=False,\n",
    "    use_elixrc=True\n",
    ")\n",
    "\n",
    "\n",
    "image_ids = dataset.get_image_ids()\n",
    "\n",
    "max_len = max([len(image_id) for image_id in image_ids])\n",
    "\n",
    "\n",
    "print(\"Max len\", max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embed(image_id, elixrc_embedding, chunk_number, output_dir):\n",
    "\n",
    "    output_path = f\"{output_dir}/elixrc_embedding_chunk_{chunk_number}.h5\"\n",
    "    with h5py.File(output_path, \"w\") as f:\n",
    "        f.create_dataset(\"elixrc_embedding\", \n",
    "                         data=np.array(elixrc_embedding), \n",
    "                         dtype=\"float32\", \n",
    "                         compression=\"gzip\", \n",
    "                         compression_opts=9)\n",
    "        \n",
    "        f.create_dataset(\"image_ids\", \n",
    "                         data=np.array(image_id, dtype=\"S\"))\n",
    "        \n",
    "        f.attrs[\"chunk_number\"] = chunk_number\n",
    "        f.attrs[\"len\"] = len(elixrc_embedding)\n",
    "        f.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "        f.attrs[\"embedding_dim\"] = elixrc_embedding[0].shape[1]\n",
    "        f.attrs[\"image_id_max_len\"] = max_len\n",
    "\n",
    "    print(f\"Saved chunk {chunk_number} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, min_size= 1024):\n",
    "    width, height = image.size\n",
    "    if width < height:\n",
    "        new_width = min_size\n",
    "        new_height = int(height * (min_size / width))\n",
    "    else:\n",
    "        new_height = min_size\n",
    "        new_width = int(width * (min_size / height))\n",
    "\n",
    "    return image.resize((new_width, new_height), Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74912fdf01ce4bbb8a7dd10a03ce1562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740600367.456283 2555143 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, image_id \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[1;32m     13\u001b[0m     image \u001b[38;5;241m=\u001b[39m resize(image, min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43melixr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     elixrc_embedding\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     18\u001b[0m     image_ids\u001b[38;5;241m.\u001b[39mappend(image_id)\n",
      "File \u001b[0;32m~/Lfstorage/Projects/cxr-diffusion/src/models/elixr.py:226\u001b[0m, in \u001b[0;36mELIXR.__call__\u001b[0;34m(self, image, text, image_embed)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Get image embedding from ELIXR-C or use provided one\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_elixrc \u001b[38;5;129;01mand\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     image_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_elixrc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melixrc_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m image_embed\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m image_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# Use provided image embedding\u001b[39;00m\n",
      "File \u001b[0;32m~/Lfstorage/Projects/cxr-diffusion/src/models/elixr.py:192\u001b[0m, in \u001b[0;36mELIXR._call_elixrc\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Run inference elixr-c\u001b[39;00m\n\u001b[1;32m    191\u001b[0m elixrc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melixrc_infer_fn(input_example \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([example]))\n\u001b[0;32m--> 192\u001b[0m elixrc_embedding \u001b[38;5;241m=\u001b[39m \u001b[43melixrc_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_maps_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elixrc_embedding\n",
      "File \u001b[0;32m~/Lfstorage/Projects/cxr-diffusion/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:415\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/Lfstorage/Projects/cxr-diffusion/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:381\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mArrayLike:\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "# Create a buffer using a queue\n",
    "buffer_size = 1000  # Adjust as needed\n",
    "image_buffer = queue.Queue(maxsize=buffer_size)\n",
    "buffer_lock = threading.Lock()\n",
    "\n",
    "# Function to fill the buffer in background\n",
    "def fill_buffer(dataset, buffer):\n",
    "    for image, image_id in dataset:\n",
    "        # Preprocess image\n",
    "        resized_img = resize(image, min_size=1024)\n",
    "        # Add to buffer (will block if buffer is full)\n",
    "        buffer.put((resized_img, image_id))\n",
    "    \n",
    "    # Add sentinel to mark the end\n",
    "    buffer.put(None)\n",
    "\n",
    "# Start the buffer filling thread\n",
    "buffer_thread = threading.Thread(target=fill_buffer, args=(dataset, image_buffer), daemon=True)\n",
    "buffer_thread.start()\n",
    "\n",
    "# Process images from buffer\n",
    "elixrc_embedding = []\n",
    "image_ids = []\n",
    "chunk_size = 10000\n",
    "chunk_count = 0\n",
    "\n",
    "# Process until we get the sentinel value\n",
    "with tqdm(total=len(dataset)) as pbar:\n",
    "    while True:\n",
    "        # Get item from buffer (will wait if buffer is empty)\n",
    "        item = image_buffer.get()\n",
    "        \n",
    "        # Check for end sentinel\n",
    "        if item is None:\n",
    "            break\n",
    "            \n",
    "        # Unpack the item\n",
    "        resized_img, image_id = item\n",
    "        \n",
    "        # Process with model\n",
    "        output = elixr_model(image=resized_img)\n",
    "        \n",
    "        # Store results\n",
    "        elixrc_embedding.append(output)\n",
    "        image_ids.append(image_id)\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Save chunk if needed\n",
    "        if len(elixrc_embedding) >= chunk_size:\n",
    "            save_embed(image_ids, elixrc_embedding, chunk_count, elixrc_path)\n",
    "            elixrc_embedding = []\n",
    "            image_ids = []\n",
    "            chunk_count += 1\n",
    "\n",
    "# Save final chunk if needed\n",
    "if len(elixrc_embedding) > 0:\n",
    "    save_embed(image_ids, elixrc_embedding, chunk_count, elixrc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "img_ids = []\n",
    "general_img_embeddings = []\n",
    "qform_img_embeddings = []\n",
    "\n",
    "# Process dataset with tqdm progress bar\n",
    "total_items = len(dataset)  # Replace with actual length if dataset doesn't support len()\n",
    "\n",
    "for image, image_id in tqdm(dataset, total=total_items, desc=\"Processing Images\", \n",
    "                           unit=\"img\", ncols=100, colour=\"green\"):\n",
    "    img_ids.append(image_id)\n",
    "    \n",
    "    # Get embeddings from model\n",
    "    output = elixr_model(image)\n",
    "    \n",
    "    # Store the embeddings\n",
    "    general_img_embeddings.append(output['general_img_embedding'])\n",
    "    qform_img_embeddings.append(output['qformer_embedding'])\n",
    "    \n",
    "\n",
    "# Convert lists to numpy arrays for saving to h5py\n",
    "img_ids = np.array(img_ids, dtype='S')\n",
    "general_img_embeddings = np.array(general_img_embeddings)\n",
    "qform_img_embeddings = np.array(qform_img_embeddings)\n",
    "\n",
    "print(f\"Processed {len(img_ids)} images\")\n",
    "print(f\"General embeddings shape: {general_img_embeddings.shape}\")\n",
    "print(f\"Q-former embeddings shape: {qform_img_embeddings.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save general embeddings\n",
    "general_img_embedding_file = output_dir + '/elixr_general_embeddings.h5'\n",
    "with h5py.File(general_img_embedding_file, 'w') as f:\n",
    "    # Create datasets with compression\n",
    "    f.create_dataset(\"embeddings\", data=general_img_embeddings, dtype=np.float32, \n",
    "                    compression=\"gzip\", compression_opts=9)\n",
    "    f.create_dataset(\"Image Index\", data=img_ids)\n",
    "    \n",
    "    # Add metadata\n",
    "    f.attrs['creation_date'] = str(datetime.now())\n",
    "    f.attrs['embedding_dim'] = general_img_embeddings.shape[1]\n",
    "    f.attrs['num_images'] = len(img_ids)\n",
    "    f.attrs['max_len'] = max_len  # Assuming max_len is defined\n",
    "\n",
    "print(f\"Saved general embeddings to {general_img_embedding_file}\")\n",
    "\n",
    "# Save Q-former embeddings\n",
    "qform_img_embedding_file = output_dir + '/elixr_qformer_embeddings.h5'\n",
    "with h5py.File(qform_img_embedding_file, 'w') as f:\n",
    "    # Create datasets with compression\n",
    "    f.create_dataset(\"embeddings\", data=qform_img_embeddings, dtype=np.float32, \n",
    "                    compression=\"gzip\", compression_opts=9)\n",
    "    f.create_dataset(\"Image Index\", data=img_ids)\n",
    "    \n",
    "    # Add metadata\n",
    "    f.attrs['creation_date'] = str(datetime.now())\n",
    "    f.attrs['embedding_dim'] = qform_img_embeddings.shape[1]\n",
    "    f.attrs['num_images'] = len(img_ids)\n",
    "    f.attrs['max_len'] = max_len  # Assuming max_len is defined\n",
    "\n",
    "print(f\"Saved Q-former embeddings to {qform_img_embedding_file}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
