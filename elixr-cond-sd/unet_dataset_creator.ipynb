{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANALYZE\n",
    "This section aims to analyze the NIH-CXR14 dataset through these operations:\n",
    "\n",
    "* **NIHDataset**: Loads tabular data and image paths from NIH-CXR14 dataset \n",
    "\n",
    "* **Field Filtering**: Selects essential columns `[\"Image Index\", \"Finding Labels\", \"Image Path\", \"embeddings\"]`\n",
    "\n",
    "* **Balance Adjustment**: Handles class imbalance using the `Finding Labels` field\n",
    "\n",
    "* **Label Exclusion**: Sets aside specific labels for validation using unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import NIHDataset\n",
    "nih_dataset = NIHDataset(\n",
    "    root_dir=os.getenv(\"NIH_CXR14_DATASET_DIR\"),\n",
    "    img_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nih_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embeddings',\n",
       " 'Image Index',\n",
       " 'Finding Labels',\n",
       " 'Follow-up #',\n",
       " 'Patient ID',\n",
       " 'Patient Age',\n",
       " 'Patient Gender',\n",
       " 'View Position',\n",
       " 'OriginalImage[Width',\n",
       " 'Height]',\n",
       " 'OriginalImagePixelSpacing[x',\n",
       " 'y]',\n",
       " 'Unnamed: 11',\n",
       " 'Image Path']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = nih_dataset.get_fields()\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embeddings', 'Image Index', 'Finding Labels', 'Image Path']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_fields = [\"Image Index\", \"Finding Labels\", \"Image Path\", \"Embeddings\"]\n",
    "\n",
    "filtered_dataset = nih_dataset.select_columns(selected_fields)\n",
    "\n",
    "fields = filtered_dataset.get_fields()\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 11559,\n",
       " 'No Finding': 60361,\n",
       " 'Consolidation': 4667,\n",
       " 'Effusion': 13317,\n",
       " 'Pleural_Thickening': 3385,\n",
       " 'Infiltration': 19894,\n",
       " 'Emphysema': 2516,\n",
       " 'Pneumothorax': 5302,\n",
       " 'Cardiomegaly': 2776,\n",
       " 'Fibrosis': 1686,\n",
       " 'Nodule': 6331,\n",
       " 'Mass': 5782,\n",
       " 'Edema': 2303,\n",
       " 'Pneumonia': 1431,\n",
       " 'Hernia': 227}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_field = filtered_dataset.get_label_counts()\n",
    "label_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering for labels: ['No Finding', 'Infiltration', 'Effusion', 'Atelectasis'], mode=include\n",
      "DataFrame shape before filtering: (112120, 3)\n",
      "\n",
      "Final label counts:\n",
      "Atelectasis: 7471\n",
      "Effusion: 7465\n",
      "Infiltration: 13240\n",
      "No Finding: 60361\n"
     ]
    }
   ],
   "source": [
    "# Hedef etiketleri belirle\n",
    "include_labels = [\"No Finding\", \"Infiltration\", \"Effusion\", \"Atelectasis\"]\n",
    "\n",
    "# Filtreleme yap\n",
    "filtered_dataset = filtered_dataset.filter_by_labels(include_labels, mode='include')\n",
    "\n",
    "# Etiket sayılarını kontrol et\n",
    "label_counts = filtered_dataset.get_label_counts()\n",
    "print(\"\\nFinal label counts:\")\n",
    "for label in sorted(label_counts.keys()):\n",
    "    print(f\"{label}: {label_counts[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## limit the number of samples per label\n",
    "filtered_dataset = filtered_dataset.limit_samples(\"No Finding\", 10000)\n",
    "filtered_dataset = filtered_dataset.limit_samples(\"Infiltration\", 10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final label counts:\n",
      "Atelectasis: 6988\n",
      "Effusion: 6918\n",
      "Infiltration: 10000\n",
      "No Finding: 10000\n"
     ]
    }
   ],
   "source": [
    "label_counts = filtered_dataset.get_label_counts()\n",
    "print(\"\\nFinal label counts:\")\n",
    "for label in sorted(label_counts.keys()):\n",
    "    print(f\"{label}: {label_counts[label]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines import VaeProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Image transformations\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "class VaeDataset():\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row, embed = self.dataset[idx]\n",
    "        image_path = row[\"Image Path\"]\n",
    "        labels = row[\"Finding Labels\"]\n",
    "        \n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Convert labels to tensor\n",
    "        if isinstance(labels, (list, np.ndarray)):\n",
    "            labels = torch.tensor([1 if label in labels else 0 for label in self.dataset.get_fields()])\n",
    "        else:\n",
    "            labels = torch.tensor([1 if label in str(labels).split('|') else 0 for label in self.dataset.get_fields()])\n",
    "        \n",
    "        # Convert embedding to tensor if it's not already\n",
    "        if isinstance(embed, np.ndarray):\n",
    "            embed = torch.from_numpy(embed)\n",
    "            \n",
    "        return image, embed, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = \"cuda:2\"\n",
    "batch_size = 16\n",
    "\n",
    "# Create dataset and dataloader\n",
    "vae_dataset = VaeDataset(filtered_dataset, transform=image_transform)\n",
    "vae_loader = DataLoader(vae_dataset, batch_size=batch_size, shuffle=False)\n",
    "vae_processor = VaeProcessor(device=device)\n",
    "\n",
    "# Setup storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2000 images\n",
      "Processed 4000 images\n",
      "Processed 6000 images\n",
      "Processed 8000 images\n",
      "Processed 10000 images\n",
      "Processed 12000 images\n",
      "Processed 14000 images\n",
      "Processed 16000 images\n",
      "Processed 18000 images\n",
      "Processed 20000 images\n",
      "Processed 22000 images\n",
      "Processed 24000 images\n",
      "Processed 26000 images\n",
      "Processed 28000 images\n",
      "Finished processing all images\n",
      "Total images processed: 29337\n"
     ]
    }
   ],
   "source": [
    "# Setup storage\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"data\")\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "storage_dictionary = {\n",
    "    'latents': {},\n",
    "    'embeddings': {},\n",
    "    'labels': {},\n",
    "}\n",
    "\n",
    "# Process data\n",
    "current_idx = 0\n",
    "for images, embeddings, labels in vae_loader:\n",
    "    # Move to device\n",
    "    images = images.to(device)\n",
    "    embeddings = embeddings.to(device)\n",
    "    \n",
    "    # Get latents\n",
    "    latents = vae_processor.prepare_latent(images)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    for latent, embed, label in zip(latents, embeddings, labels):\n",
    "        storage_dictionary['latents'][current_idx] = latent.cpu().detach().numpy()\n",
    "        storage_dictionary['embeddings'][current_idx] = embed.cpu().detach().numpy()\n",
    "        storage_dictionary['labels'][current_idx] = label.cpu().numpy()\n",
    "        current_idx += 1\n",
    "    \n",
    "    # Periodic saving\n",
    "    if current_idx % 1000 == 0:\n",
    "        print(f\"Processed {current_idx} images\")\n",
    "        with open(save_dir / \"nih-cxr14-latent-embed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(storage_dictionary, f)\n",
    "\n",
    "# Final save\n",
    "with open(save_dir / \"nih-cxr14-latent-embed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(storage_dictionary, f)\n",
    "\n",
    "print(\"Finished processing all images\")\n",
    "print(f\"Total images processed: {current_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
